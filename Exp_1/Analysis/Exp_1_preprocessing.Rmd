---
title: "Pilot Analysis"
author: "Will Clapp"
date: "8/25/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(psych)
library(lme4)
library(lmerTest)
```


Load data
```{r}
df.data <- read.csv("/Users/willclapp/Desktop/QP1/QP1_Experiments/Exp_1/Analysis/Exp_1_raw.csv")
```


Remove any trials that took longer than 4 seconds (including the 1-second ISI) or less than one second (which means they somehow got around the ISI. Not sure how people did this.)
This knocks us down from the original 72220 obs. to 67269 (4951 observations lost)
```{r}
df.data <- df.data %>% 
  filter(trial_time.1 < 4) %>%
  filter(trial_time.1 > 1)

```

Now we need to see if removing those observations means that certain people don't actually sufficient exposure to critical ambiguous items
```{r}
df.no_crit_amb <- df.data %>% 
  filter(type == "crit_amb" | type == "crit_unamb") %>% 
  group_by(participant_id, type) %>% 
  tally() %>% 
  filter(n < 10)
```


We probably shouldn't include people who missed at least 10 critical words from either the critical ambiguous or unambiguous set. It looks like this removes three further people. (67269 obs. to 66618 obs.)
```{r}
df.data <-  df.data %>% 
  filter(!(participant_id %in% df.no_crit_amb$participant_id))

```


Create a binary variable where a "yes" response is 1 and "no" is 0
```{r}
df.data <- df.data %>% 
  mutate(response_01 = ifelse(response=="yes", 1, 0))

```

Add a centered version of step that's sensitive to the midpoint of each continuum identified by the norming experiments

```{r}
df.data <- df.data %>% 
  mutate("step_dist" = (step - normed_midpoint)) %>% 
  mutate("side_length" = ifelse((step>normed_midpoint), (30-normed_midpoint), (normed_midpoint))) %>% 
  mutate("norm_step" = step_dist/side_length)

```

And a mean-centered version of regular step too
```{r}
# mean center it
df.data = df.data %>% 
  mutate("c_step" = scale(step, scale=FALSE))
```

Add column for accuracy on exposure
```{r}
df.data <- df.data %>% 
  mutate("accurate" = ifelse(((phase=="exposure") & (((response=="yes") & (correct=="yes")) | ((response=="no") & (correct=="no")))), 1, 0))

df.data <- df.data %>% 
  mutate("accurate" = ifelse((phase=="exposure"), accurate, NA))

df.accuracy = df.data %>% 
  filter(phase == "exposure") %>% 
  group_by(participant_id, time_in_minutes) %>% 
  summarise(accuracy_exposure = mean(accurate))

df.data = left_join(df.data, df.accuracy, by="participant_id")

```



Add another column representing accuracy on test. This will be defined as the percentage of unambiguous stims that were categorized correctly.
```{r}
df.0_30 <- df.data %>% 
  filter(phase == "test" & (step == 0 | step == 30))

df.0_30 <- df.0_30 %>% 
  mutate("accurate_test" = ifelse(((response=="yes" & step == 30) | (response == "no" & step == 0)), 1, 0))


df.accuracy_test = df.0_30 %>% 
  group_by(participant_id) %>% 
  summarise(accuracy_test = mean(accurate_test))

df.data = left_join(df.data, df.accuracy_test, by="participant_id")

```




create two DFs, where `df.guessers` consists of removed participants and `df.listeners` consists of data to be analyzed. Current cutoff is 95% on exposure and 90% on test
```{r}
df.guessers <- df.data %>% 
  filter(accuracy_exposure < 0.95 | accuracy_test < 0.9)

df.listeners <- df.data %>% 
  filter(accuracy_exposure >= 0.95 & accuracy_test >= 0.9)
```


Time to figure out how many people are in each group. Looks like we kept 115 and filtered 38
```{r}
df.groups_listeners <- df.listeners %>% 
  distinct(participant_id, .keep_all = TRUE)

df.macro_groups_listeners <- df.groups_listeners %>% 
  group_by(group) %>% 
  tally()

df.groups_guessers <- df.guessers %>% 
  distinct(participant_id, .keep_all = TRUE)

df.macro_groups_guessers <- df.groups_guessers %>% 
  group_by(group) %>% 
  tally()

```


Add a column to the main df.data file indicating whether or not a participant was excluded
```{r}
df.data <- df.data %>% 
  mutate("included" = ifelse((participant_id %in% df.groups_guessers$participant_id), 0, 1))

```


Visualize the critical ambiguous words to see how often people categorized them as expected. This looks pretty good. 
```{r}
df.listeners %>%
  filter(type == "crit_amb" & group != "control") %>% 
  ggplot(aes(x = accurate)) +
  geom_bar() +
  facet_wrap(~audio)

```

Accuracy on exposure
```{r}
df.exposure = df.data %>% 
  filter(phase == "exposure")

# df.exposure$group <- relevel(df.exposure$group,"control", "B_group", "P_group")

mean(df.exposure$accuracy_exposure)

df.bcrit = df.exposure %>% 
  filter(group=="B_group") %>% 
  filter(type == "crit_amb") 

mean(df.bcrit$accuracy_exposure)

df.pcrit = df.exposure %>% 
  filter(group=="P_group") %>% 
  filter(type == "crit_amb") 

mean(df.pcrit$accuracy_exposure)

df.crit = df.exposure %>% 
  filter(type == "crit_amb")

```

# ```{r}
# df.exposure <- df.exposure %>% 
#   mutate("accuracy_exposure" = as.numeric(accuracy_exposure))
# 
# glm.norm_listeners = glm(response_01 ~ 1 + group * norm_step, 
#                      data = df.data,
#                      family="binomial")
# 
# glmer.exposure = glmer(accuracy_exposure ~ 1 + group + slide_order + (1 | participant_id),
#                    family = "binomial",
#                    data = df.crit)
# 
# summary(glmer.exposure)
# 
# ```



Then make a DF that consists only of the test phase and only included participants
```{r}
df.listeners_test <-df.listeners %>% 
  filter(phase == "test")

```



That should do it for pre-processing.

```{r}
# write.csv(df.listeners_test, "/Users/willclapp/Desktop/QP1/QP1_Experiments/Exp_1/Analysis/Exp_1_preprocessed.csv")

```






__________________________________________________________________________________________________
__________________________________________________________________________________________________
__________________________________________________________________________________________________
__________________________________________________________________________________________________
__________________________________________________________________________________________________



```{r}
step_means = df.listeners_test %>% 
  group_by(voiced_sel, group, step) %>% 
  summarise('step_mean' = mean(response_01))

ggplot(data = step_means,
       mapping = aes(x = step,
                     y = step_mean)) +
  geom_point(aes(color = group)) +
  facet_grid(~voiced_sel) +
  geom_smooth(aes(color = group),
              se = FALSE)

```


Okay, now getting stats for the write up. 


```{r}
df.all_data <- read.csv("/Users/willclapp/Desktop/QP1/QP1_Experiments/Exp_1/Analysis/Exp_1_raw.csv")

```

How many total participants?

```{r}
72220/460
# 157

```

Average time?
```{r}
df.one_trial <-  df.all_data %>% 
  filter(audio == "Violin")

mean(df.one_trial$time_in_minutes)
# = 25.6

#compensation = 4.76

(60*4.76)/25.6




```



```{r}
mean(df.one_trial$age)


summary(df.one_trial$age)


```


```{r}
df.all_test <- df.all_data %>% 
  filter(phase == "test") 


mean(df.all_test$normed_midpoint)


```


Accuracy on exposure
```{r}



```







